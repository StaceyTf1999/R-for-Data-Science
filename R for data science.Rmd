---
title: "r4ds"
output: html_document
date: '2022-06-03'
---

# 3 data visualization


```{r geom_point}
# ggplot2
library(tidyverse)
mpg
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = class, y = drv) )

#geom_point() adds a layer of points to your plot, which creates a scatterplot
#Each geom function in ggplot2 takes a mapping argument. The mapping argument is always paired with aes()
```

```{r color alpha shape size}
#Aesthetics include things like the size, the shape, or the color of your points.
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, color = class))

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, alpha = class))

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, shape = class))
#ggplot2 will only use six shapes at a time. 

ggplot(data=mpg) + 
  geom_point(mapping = aes(x=displ, y=hwy, size = cty))


#  "+" has to come at the end of the line, not the start
```


```{r facets}
# Facets

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_wrap(~ class, nrow = 2)
# facet_wrap() should be a formula, which you create with ~ followed by a variable name
```

```{r geom+smooth}
ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy))


ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv))



ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) +
  geom_smooth(mapping = aes(x = displ, y = hwy))



ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point(mapping = aes(color = class)) + 
  geom_smooth()

```

```{r stat}

# stat = count/frequency/ prop
library(tidyverse)
diamonds

#Count
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut))

#Proportion
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = stat(prop), group = 1))

#summary
ggplot(data = diamonds) + 
  stat_summary(
    mapping = aes(x = cut, y = depth),
    fun.min = min,
    fun.max = max,
    fun = median
  )


```


```{r count+group by}
diamonds %>% 
  group_by(cut) %>%
  count(clarity)

diamonds%>%
  count(cut)
```


```{r bar chart+fill & position}
#Fill the color
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = cut))

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity))


ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "fill")
# position = fill是百分比柱状图

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "dodge")
#dodge是分开填充颜色

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "stack")
```


```{r coordinate system}
#Coordinate systems

# coord_flip() switches the x and y axes.
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + 
  geom_boxplot()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + 
  geom_boxplot() +
  coord_flip()
```
```{r coord_quickmap}
#coord_quickmap() sets the aspect ratio correctly for maps.
nz <- map_data("nz")

ggplot(nz, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", colour = "black")

ggplot(nz, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", colour = "black") +
  coord_quickmap()
```




```{r coord_polar()}
#coord_polar() uses polar coordinates. Polar coordinates reveal an interesting connection between a bar chart and a Coxcomb chart.

bar <- ggplot(data = diamonds) + 
  geom_bar(
    mapping = aes(x = cut, fill = cut), 
    show.legend = FALSE,
    width = 1
  ) + 
  theme(aspect.ratio = 1) +
  labs(x = NULL, y = NULL)

bar + coord_flip()
bar + coord_polar()

```

##ggplot2绘图代码整合！

ggplot(data = <DATA>) + 
  <GEOM_FUNCTION>(
     mapping = aes(<MAPPINGS>),
     stat = <STAT>, 
     position = <POSITION>
  ) +
  <COORDINATE_FUNCTION> +
  <FACET_FUNCTION>

The grammar of graphics is based on the insight that you can uniquely describe any plot as a combination of a dataset, a geom, a set of mappings, a stat, a position adjustment, a coordinate system, and a faceting scheme.


```{r add taps}
#每个柱子添加数据
mpg %>% 
  group_by(class, drv) %>% 
  summarise(count = n()) %>%
  ggplot(aes(class, count)) +
  geom_col(aes(fill=drv), position = position_dodge2(preserve = 'single')) +
  geom_text(aes(label=count), 
            position = position_dodge2(width = 0.8, preserve = 'single'), 
            vjust = -0.5, hjust = 0.5)
```






# 4 Workflow: basics
```{r basics}
1 / 200 * 30
sin(pi / 2)
x <- "hello world"
x
this_is_a_really_long_name <- 2.5
this_is_a_really_long_name
r_rocks <- 2 ^ 3
r_rocks
```

## Alt和-号可以摁出 <- 
## Tab可以快速选择自动弹出的字符

```{r seq}
seq(1,10)
(y <- seq(1,10, length.out = 5))
```





# 5 Data Transformation: dplyr


```{r run library}
library(nycflights13)
library(tidyverse)
flights
```
## 数据类型
int stands for integers.

dbl stands for doubles, or real numbers.

chr stands for character vectors, or strings.

dttm stands for date-times (a date + a time).

lgl stands for logical, vectors that contain only TRUE or FALSE.

fctr stands for factors, which R uses to represent categorical variables with fixed possible values.

date stands for dates.

## five functions in dplyr
Pick observations by their values *filter()*.
Reorder the rows *arrange()*.
Pick variables by their names *select()*
Create new variables with functions of existing variables *mutate()*
Collapse many values down to a single summary *summarise()*
These can all be used in conjunction with *group_by()* which changes the scope of each function from operating on the entire dataset to operating on it group-by-group.

## 1) filter
```{r filter}
filter(flights, month == 1, day == 1)
jan1 <- filter(flights, month == 1, day == 1)
filter(flights, month == 11 | month == 12)
filter(flights, month %in% c(11, 12))
filter(flights, is.na(dep_time))
```
If you want to determine if a value is missing, use *is.na()*

```{r is.na}
x <- NA
is.na(x)
```

```{r is.na}
df <- tibble(x = c(1, NA, 3))
df
filter(df, x > 1)
filter(df, is.na(x) | x > 1)

```


# 2) arrange

```{r arrange}
#降序
arrange(flights, desc(dep_delay))
#升序，不需要多一个函数
arrange(flights,dep_delay)
```

# 3) select

```{r select the column}
select(flights, month, year, day)
select(flights, year:day)  #从year到day的列
select(flights, -(year:day))  #不要year到day的列

select(flights, starts_with("dep"))
```


# 4) mutate: add variables
```{r}
flights_sml <- select(flights, 
  year:day, 
  ends_with("delay"), 
  distance, 
  air_time
)

mutate(flights_sml,
  gain = dep_delay - arr_delay,
  speed = distance / air_time * 60
)


#If you only want to keep the new variables, use transmute():
transmute(flights,
  gain = dep_delay - arr_delay,
  hours = air_time / 60,
  gain_per_hour = gain / hours
)
```

%/% (integer division) and %% (remainder)

## lead() and lag() 
```{r}
(x <- 1:10)
lag(x)  #往后推
lead(x)  #向前进
```

##累加 cumsum（）& Rank
```{r}
x
cumsum(x)
cummean(x)
y <- c(1, 2, 2, NA, 4, 3)
min_rank(y)
```


# 5) summarise()


```{r summarise mean}
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))

#Together group_by() and summarise() provide one of the tools that you’ll use most commonly when working with dplyr
by_day <- group_by(flights, year, month, day)
summarise(by_day, delay = mean(dep_delay, na.rm = TRUE))
```


```{r group_by + summarise}
dest <- group_by(flights, dest)
delay <- summarise(dest, 
  count = n(), 
  dist = mean(distance, na.rm = TRUE), 
  delay = mean(arr_delay, na.rm = TRUE)
  )
delay
```

```{r pipe}
delay <- flights %>% 
  group_by(dest) %>% 
  summarise(
    count = n(),
    dist = mean(distance, na.rm = TRUE),
    delay = mean(arr_delay, na.rm = TRUE)
  ) %>% 
  filter(count > 20, dest != "HNL")
delay


ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
  geom_point(aes(size = count), alpha = 1/3) +
  geom_smooth(se = FALSE)
```

it’s always a good idea to include either a *count (n())*, or a count of non-missing values *sum(!is.na(x))* 


```{r remove missing data}
not_cancelled <- flights %>% 
  filter(!is.na(dep_delay), !is.na(arr_delay))

not_cancelled

delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarise(
    count = n(), 
    delay = mean(arr_delay)
  )
delays

ggplot(data = delays, mapping = aes(x = delay)) + 
  geom_freqpoly(binwidth = 10)
```


```{r summarise & filter count}
delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarise(
    delay = mean(arr_delay, na.rm = TRUE),
    n = n()
  )


ggplot(data = delays, mapping = aes(x = n, y = delay)) + 
  geom_point(alpha = 1/10)


delays %>% 
  filter(n > 25) %>% 
  ggplot(mapping = aes(x = n, y = delay)) + 
    geom_point(alpha = 1/10)

```


```{r comprehensive usage}
# Convert to a tibble so it prints nicely
Lahman::Batting
batting <- as_tibble(Lahman::Batting)


#ba:skill of the batter, 打中次数/attemp次数
#ab:the number of opportunities to hit the ball
batters <- batting %>% 
  group_by(playerID) %>% 
  summarise(
    ba = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),
    ab = sum(AB, na.rm = TRUE)
  )

batters

batters %>% 
  filter(ab > 100) %>%   #尝试次数大于100

  


  ggplot(mapping = aes(x = ab, y = ba)) +
    geom_point() + 
    geom_smooth(se = FALSE)


batters %>% 
  arrange(desc(ba))
```

The interquartile range *IQR(x)* and median absolute deviation *mad(x)* are robust equivalents that may be more useful if you have outliers.


To count the number of non-missing values, use *sum(!is.na(x))*. To count the number of distinct (unique) values, use *n_distinct(x)*.
```{r application}
# Which destinations have the most carriers?
not_cancelled %>% 
  group_by(dest) %>% 
  summarise(carriers = n_distinct(carrier)) %>% 
  arrange(desc(carriers))


#单纯的count每一个目的地有多少
not_cancelled %>% 
  count(dest)
```

```{r sum()}
x <- c(1:13)
sum(x > 10)

```
sum(x>=3)是求向量中大于等于3的数的个数的和
length(x>=3)返回的值为FALSE FALSE TRUE TRUE TRUE ，一共5个

大于等于3的长度：
sum(x>=3) 或 length(x[x>=3])


Counts and proportions of logical values: sum(x > 10), mean(y == 0). When used with numeric functions, TRUE is converted to 1 and FALSE to 0. This makes sum() and mean() very useful: sum(x) gives the number of TRUEs in x, and mean(x) gives the proportion.

```{r application}
# How many flights left before 5am?
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(n_early = sum(dep_time < 500))



# What proportion of flights are delayed by more than an hour?
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(hour_prop = mean(arr_delay > 60))
```


```{r Grouping by multiple variables}
daily <- group_by(flights, year, month, day)
(per_day   <- summarise(daily, flights = n()))

(per_month <- summarise(per_day, flights = sum(flights)))

(per_year  <- summarise(per_month, flights = sum(flights)))
```


```{r Ungrouping}
daily %>% 
  ungroup() %>%             # no longer grouped by date
  summarise(flights = n())  # all flights

```

```{r application}
# 找到最热门的目的地
popular_dests <- flights %>% 
  group_by(dest) %>% 
  filter(n() > 365)
popular_dests
```


```{r application}
library(dplyr)
library(nycflights13)

not_cancelled <- flights %>% 
  filter(!is.na(dep_delay), !is.na(arr_delay))

not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay))
```






# 7 EDA

# 7-1 one variable
```{r bar chart and histogram}
library(tidyverse)
ggplot(data = diamonds) +
  geom_bar(mapping = aes(x = cut))



# continuous变量用histogram
ggplot(data = diamonds) +
  geom_histogram(mapping = aes(x = carat), binwidth = 0.5)

diamonds %>% 
  count(cut_width(carat, 0.5))


```

# 7-2 categorical with continious variables
If you wish to overlay multiple histograms in the same plot, I recommend using *geom_freqpoly()* instead of geom_histogram().

```{r freqpoly}
smaller <- diamonds %>% 
  filter(carat < 3)
  
ggplot(data = smaller, mapping = aes(x = carat)) +
  geom_histogram(binwidth = 0.1)

ggplot(data = smaller, mapping = aes(x = carat, colour = cut)) +
  geom_freqpoly(binwidth = 0.1)
```
If outliers have a substantial effect on your results, you shouldn’t drop them without justification. You’ll need to figure out what caused them (e.g. a data entry error) and disclose that you removed them in your write-up.

# 7-3 如何观测到outliers?   coord_cartesian()

```{r}
ggplot(diamonds) + 
  geom_histogram(mapping = aes(x = y), binwidth = 0.5) +
  coord_cartesian(ylim = c(0, 50))  #zoom to small values of the y-axis
#This allows us to see that there are three unusual values: 0, ~30, and ~60.


#choose these unusual observations: 
unusual <- diamonds %>% 
  filter(y < 3 | y > 20) %>% 
  select(price, x, y, z) %>%
  arrange(y)
unusual
```

# 7-4 Deal with outliers
1. Drop the entire row with the strange values:
diamonds2 <- diamonds %>% 
  filter(between(y, 3, 20))
2. recommend replacing the unusual values with missing values:
```{r convert into missing value}
diamonds2 <- diamonds %>% 
  mutate(y = ifelse(y < 3 | y > 20, NA, y)) #如果y小于3or大于20，将y=NA；否则=本身

ggplot(data = diamonds2, mapping = aes(x = x, y = y)) + 
  geom_point(na.rm = TRUE)


nycflights13::flights %>% 
  mutate(
    cancelled = is.na(dep_time),
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + sched_min / 60
  ) %>% 
  ggplot(mapping = aes(sched_dep_time)) + 
    geom_freqpoly(mapping = aes(colour = cancelled), binwidth = 1/4)
# True,被取消的，False，没被取消的
```
#7-5 display density ：standardised count 
当每一个类别的数量差别很大，用count不好，要用density

```{r density}
library(tidyverse)
ggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) + 
  geom_freqpoly(mapping = aes(colour = cut), binwidth = 500)
```
Another alternative to display the distribution of a continuous variable broken down by a categorical variable is the *boxplot*

Visual points that display observations that fall more than 1.5 times the IQR from either edge of the box. These outlying points are unusual so are plotted individually

```{r boxplot}


ggplot(data = diamonds, mapping = aes(x = cut, y = price)) +
  geom_boxplot()


#Some variables do not have order, we could reorder them according to their y-value

#reorder class based on the median value of hwy
ggplot(data = mpg) +
  geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy))


#If you have long variable names, geom_boxplot() will work better if you flip it 90°. You can do that with coord_flip().

ggplot(data = mpg) +
  geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) +
  coord_flip()
```

# 7-6 two catevorical variables
count the number of observations for each combination. One way to do that is to rely on the built-in *geom_count()*

```{r geom_count and geom_tile()}
ggplot(data = diamonds) +
  geom_count(mapping = aes(x = cut, y = color))

#Another approach is to compute the count with dplyr:
diamonds %>% 
  count(color, cut)
#Then visualise with geom_tile() and the fill aesthetic:
diamonds %>% 
  count(color, cut) %>%  
  ggplot(mapping = aes(x = color, y = cut)) +
    geom_tile(mapping = aes(fill = n))


```
# 7-7 two continuous variables 

```{r geom_point}
ggplot(data = diamonds) +
  geom_point(mapping = aes(x = carat, y = price))

#当数据量非常大的时候，using the alpha aesthetic to add transparency.

ggplot(data = diamonds) + 
  geom_point(mapping = aes(x = carat, y = price), alpha = 1 / 100)

diamonds
```

当2个continuous的数据量非常大，use geom_bin2d() and geom_hex() to bin in two dimensions.

geom_bin2d() and geom_hex() divide the coordinate plane into 2d bins and then use a fill color to display how many points fall into each bin. geom_bin2d() creates rectangular bins. geom_hex() creates hexagonal bins. 

```{r geom_bin2d() and geom_hex()}
ggplot(data = smaller) +
  geom_bin2d(mapping = aes(x = carat, y = price))

ggplot(data = smaller) +
  geom_hex(mapping = aes(x = carat, y = price))

```
Another option is to bin one continuous variable so it acts like a categorical variable.

```{r bin one continuous variable}
ggplot(data = smaller, mapping = aes(x = carat, y = price)) + 
  geom_boxplot(mapping = aes(group = cut_width(carat, 0.1)))  #group carat as categorical variable, divides carat into bins of width 

ggplot(data = smaller, mapping = aes(x = carat, y = price)) + 
  geom_boxplot(mapping = aes(group = cut_number(carat, 20)))  #每一个cut里面保证number of point=20，而不是用等宽的carat来group

```

```{r glimpse}
glimpse(diamonds)
```

# 7-8 Building models 


```{r}
library(modelr)

mod <- lm(log(price) ~ log(carat), data = diamonds)

diamonds2 <- diamonds %>% 
  add_residuals(mod) %>% 
  mutate(resid = exp(resid))

#The residuals give us a view of the price of the diamond, once the effect of carat has been removed

ggplot(data = diamonds2) + 
  geom_point(mapping = aes(x = carat, y = resid))

#Once you’ve removed the strong relationship between carat and price, you can see what you expect in the relationship between cut and price:

ggplot(data = diamonds2) + 
  geom_boxplot(mapping = aes(x = cut, y = resid))

```

The first two arguments to ggplot() are data and mapping, and the first two arguments to aes() are x and y.

```{r summary}
diamonds %>% 
  count(clarity, cut) %>%
  ggplot(aes(clarity, cut, fill = n)) + 
    geom_tile()

diamonds %>% 
  ggplot(aes(clarity, cut)) + 
  geom_count()

diamonds %>%
  ggplot(aes(cut, fill = clarity)) + 
  geom_bar()
```

# 10 Tibbles

```{r coerce a data frame to a tibble}
library(tidyverse)
as_tibble(iris)
```
```{r creat tibble}
tibble(
  x = 1:5, 
  y = 1, 
  z = x ^ 2 + y
)
```

It’s possible for a tibble to have column names that are not valid R variable names. To refer to these variables, you need to surround them with backticks, `:
```{r tibble column names}
tb <- tibble(
  `:)` = "smile", 
  ` ` = "space",
  `2000` = "number"
)
tb
```
```{r tribble}
tribble(
  ~x, ~y, ~z,

  "a", 2, 3.6,
  "b", 1, 8.5
)
```

# 11 data import

```{r readr package}
library(tidyverse)

#read_csv: They produce tibbles, they don’t convert character vectors to factors, use row names, or munge the column names. These are common sources of frustration with the base R functions

height <- read_csv("Height of Male and Female.csv", show_col_types = FALSE)

height

#can use skip=n to skip first n rows when read_csv
#use col_name = FALSE to tell R that there is no column name in the csv file

# \n : adding new line


#na: this specifies the value that are used to represent missing values in your file:
read_csv("a,b,c\n1,2,.", na = ".")
```

```{r parse function}
parse_integer(c("1", "231", ".", "456"), na = ".")
```
# parse function: turn characters into expression

## numbers
```{r locale}
# problem 1: People write numbers differently in different parts of the world. For example, some countries use . in between the integer and fractional parts of a real number, while others use ,.

parse_double("1.23")

parse_double("1,23", locale = locale(decimal_mark = ","))

#用locale将“，”变成“.” 




```


```{r parse number}
# problem 2: Numbers are often surrounded by other characters that provide some context, like “$1000” or “10%”.

parse_number("$100")

parse_number("20%")

parse_number("It cost $123.45")

```


```{r parse_number + locale}
#problem 3: Numbers often contain “grouping” characters to make them easier to read, like “1,000,000”, and these grouping characters vary around the world.

# Used in America
parse_number("$123,456,789")


# Used in many parts of Europe
parse_number("123.456.789", locale = locale(grouping_mark = "."))


# Used in Switzerland
parse_number("123'456'789", locale = locale(grouping_mark = "'"))

```

## Strings
```{r charToRaw: encode}
charToRaw("Hadley")


# UTF-8： famous encoding standard
#lecture: 11.3.2
```


## factors

```{r parse_factor}
fruit <- c("apple", "banana")
parse_factor(c("apple", "banana", "bananana"), levels = fruit)
```

## Dates, date-times, and times
```{r parse_datetime}
parse_datetime("2010-10-01T2010")
parse_datetime("20101010")

parse_date("2010-10-01")

library(hms)
parse_time("01:10 am")

parse_time("20:10:01")

```
```{r change the time format}
parse_date("01/02/15", "%m/%d/%y")

parse_date("01/02/15", "%d/%m/%y")

parse_date("01/02/15", "%y/%m/%d")
```

## Parsing a file

```{r guess_parser} 
guess_parser("2010-10-01")
guess_parser(c("TRUE", "FALSE"))
guess_parser(c("12,352,561"))

```

```{r change column type}
library(tidyverse)
challenge <- read_csv(readr_example("challenge.csv"))

problems(challenge)

tail(challenge)

challenge <- read_csv(
  readr_example("challenge.csv"), 
  col_types = cols(
    x = col_double(),
    y = col_date()
  )
)
tail(challenge)


```

```{r}
challenge2 <- read_csv(readr_example("challenge.csv"), 
  col_types = cols(.default = col_character())
)
challenge2
```

## Writing to a file
readr also comes with two useful functions for writing data back to disk: *write_csv()* and write_tsv(). Both functions increase the chances of the output file being read back in correctly by:

Always encoding strings in *UTF-8*.

Saving dates and date-times in *ISO8601* format so they are easily parsed elsewhere.